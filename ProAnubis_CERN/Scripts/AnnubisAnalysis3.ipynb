{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot activate multiple GUI eventloops\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'AnubisSuperScript' from 'c:\\\\Users\\\\Peter\\\\OneDrive - University of Cambridge\\\\Desktop\\\\Project Excel Work\\\\PartIIIRPC\\\\ProAnubis_CERN\\\\Scripts\\\\AnubisSuperScript.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import anubisPlotUtils as anPlot\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import hist as hi\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "import matplotlib.colors as colors\n",
    "matplotlib.use('TkAgg')  # or 'Qt5Agg', 'GTK3Agg', etc.\n",
    "import mplhep as hep\n",
    "hep.style.use([hep.style.ATLAS])\n",
    "import sys\n",
    "import AnalysisToolAnubis as AT\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from pandasgui import show\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.ndimage import label, find_objects\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import sys\n",
    "from scipy.stats import gaussian_kde\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import AnubisSuperScript as ass\n",
    "from functools import partial\n",
    "import importlib\n",
    "importlib.reload(ass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mapping = {\n",
    "    0: {\n",
    "        (0, 31): ('rpc0', 'eta'),\n",
    "        (32, 63): ('rpc0', 'phi1'),\n",
    "        (64, 95): ('rpc0', 'phi2'),\n",
    "        (96, 127): ('rpc1', 'eta'),\n",
    "    },\n",
    "    1: {\n",
    "        (0, 31): ('rpc1', 'phi1'),\n",
    "        (32, 63): ('rpc1', 'phi2'),\n",
    "        (64, 95): ('rpc2', 'eta'),\n",
    "        (96, 127): ('rpc2', 'phi1'),\n",
    "    },\n",
    "    2: {\n",
    "        (0, 31): ('rpc2', 'phi2'),\n",
    "        (32, 63): ('rpc3', 'eta'),\n",
    "        (64, 95): ('rpc3', 'phi1'),\n",
    "        (96, 127): ('rpc3', 'phi2'),\n",
    "    },\n",
    "    3: {\n",
    "        (0, 31): ('rpc4', 'eta'),\n",
    "        (32, 63): ('rpc4', 'phi1'),\n",
    "        (64, 95): ('rpc4', 'phi2'),\n",
    "        (96, 127): ('rpc5', 'eta'),\n",
    "    },\n",
    "    4: {\n",
    "        (0, 31): ('rpc5', 'phi1'),\n",
    "        (32, 63): ('rpc5', 'phi2'),\n",
    "    },\n",
    "}\n",
    "\n",
    "strips_on_steroid = {\n",
    "    'rpc0': {'phi': [0]},\n",
    "    'rpc1': {'phi': [0]},\n",
    "    'rpc2': {'phi': [0]},\n",
    "    'rpc3': {'phi': [0]},\n",
    "    'rpc4': {'eta': [31,0], 'phi': [0]},\n",
    "    'rpc5': {'eta': [31,0], 'phi': [0]},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisData = AT.importDatafile('C:\\\\Users\\\\Peter\\\\OneDrive - University of Cambridge\\\\Desktop\\\\Project Excel Work\\\\PartIIIRPC\\\\ProAnubis_CERN\\\\ProAnubisData\\\\60sRun_24_3_4.h5')\n",
    "df = ass.remake_data(thisData, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = ass.calculate_cluster_metrics_better(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_noisy_strips_with_map = partial(ass.remove_noisy_strips, noisy_strips=strips_on_steroid)\n",
    "anti_steriod_df = cluster_df[cluster_df.apply(lambda row: remove_noisy_strips_with_map(row), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_massaged_df = anti_steriod_df[anti_steriod_df['size'] <= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(anti_steriod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "INFO:pandasgui.gui:Opening PandasGUI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x23406a801f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(fully_massaged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "INFO:pandasgui.gui:Opening PandasGUI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x1de76445d80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(cluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path1 = 'C:\\\\Users\\\\Peter\\\\OneDrive - University of Cambridge\\\\Desktop\\\\Project Excel Work\\\\PartIIIRPC\\\\ProAnubis_CERN\\\\ProAnubis Plots\\\\OG3\\\\rpc_cluster_analysis_all.pdf'\n",
    "pdf_path2 = 'C:\\\\Users\\\\Peter\\\\OneDrive - University of Cambridge\\\\Desktop\\\\Project Excel Work\\\\PartIIIRPC\\\\ProAnubis_CERN\\\\ProAnubis Plots\\\\OG3\\\\rpc_cluster_analysis_anti_steriod.pdf'\n",
    "# ass.plot_rpc_histograms(cluster_df, pdf_path1)\n",
    "ass.plot_rpc_histograms(anti_steriod_df, pdf_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path3 = 'C:\\\\Users\\\\Peter\\\\OneDrive - University of Cambridge\\\\Desktop\\\\Project Excel Work\\\\PartIIIRPC\\\\ProAnubis_CERN\\\\ProAnubis Plots\\\\OG3\\\\rpc_cluster_analysis_by_size.pdf'\n",
    "ass.plot_rpc_histograms_by_cluster_size(anti_steriod_df, pdf_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m pdf_path4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mPeter\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOneDrive - University of Cambridge\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mProject Excel Work\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mPartIIIRPC\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mProAnubis_CERN\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mProAnubis Plots\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOG3\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mrpc_cluster_time_analysis.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m fully_massaged_df_with_time \u001b[38;5;241m=\u001b[39m fully_massaged_df[fully_massaged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m350\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m \u001b[43mass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_time_differences_and_event_times\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfully_massaged_df_with_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdf_path4\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Peter\\OneDrive - University of Cambridge\\Desktop\\Project Excel Work\\PartIIIRPC\\ProAnubis_CERN\\Scripts\\AnubisSuperScript.py:491\u001b[0m, in \u001b[0;36mplot_time_differences_and_event_times\u001b[1;34m(df, pdf_path)\u001b[0m\n\u001b[0;32m    487\u001b[0m grouped_by_event \u001b[38;5;241m=\u001b[39m filtered_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_number\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    489\u001b[0m time_differences \u001b[38;5;241m=\u001b[39m []  \n\u001b[1;32m--> 491\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event_number, event_group \u001b[38;5;129;01min\u001b[39;00m grouped_by_event:\n\u001b[0;32m    492\u001b[0m     event_group_sorted \u001b[38;5;241m=\u001b[39m event_group\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    494\u001b[0m     diffs \u001b[38;5;241m=\u001b[39m event_group_sorted[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdiff()\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[1;32mc:\\Users\\Peter\\OneDrive - University of Cambridge\\Desktop\\Project Excel Work\\PartIIIRPC\\.venv\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:790\u001b[0m, in \u001b[0;36mBaseGrouper.get_iterator\u001b[1;34m(self, data, axis)\u001b[0m\n\u001b[0;32m    788\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_splitter(data, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    789\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_keys_seq\n\u001b[1;32m--> 790\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, splitter)\n",
      "File \u001b[1;32mc:\\Users\\Peter\\OneDrive - University of Cambridge\\Desktop\\Project Excel Work\\PartIIIRPC\\.venv\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:1332\u001b[0m, in \u001b[0;36mDataSplitter.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1329\u001b[0m starts, ends \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mgenerate_slices(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslabels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups)\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start, end \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(starts, ends):\n\u001b[1;32m-> 1332\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chop\u001b[49m\u001b[43m(\u001b[49m\u001b[43msdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Peter\\OneDrive - University of Cambridge\\Desktop\\Project Excel Work\\PartIIIRPC\\.venv\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:1357\u001b[0m, in \u001b[0;36mFrameSplitter._chop\u001b[1;34m(self, sdata, slice_obj)\u001b[0m\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chop\u001b[39m(\u001b[38;5;28mself\u001b[39m, sdata: DataFrame, slice_obj: \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   1352\u001b[0m     \u001b[38;5;66;03m# Fastpath equivalent to:\u001b[39;00m\n\u001b[0;32m   1353\u001b[0m     \u001b[38;5;66;03m# if self.axis == 0:\u001b[39;00m\n\u001b[0;32m   1354\u001b[0m     \u001b[38;5;66;03m#     return sdata.iloc[slice_obj]\u001b[39;00m\n\u001b[0;32m   1355\u001b[0m     \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m     \u001b[38;5;66;03m#     return sdata.iloc[:, slice_obj]\u001b[39;00m\n\u001b[1;32m-> 1357\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43msdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1358\u001b[0m     df \u001b[38;5;241m=\u001b[39m sdata\u001b[38;5;241m.\u001b[39m_constructor(mgr)\n\u001b[0;32m   1359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39m__finalize__(sdata, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pdf_path4 = 'C:\\\\Users\\\\Peter\\\\OneDrive - University of Cambridge\\\\Desktop\\\\Project Excel Work\\\\PartIIIRPC\\\\ProAnubis_CERN\\\\ProAnubis Plots\\\\OG3\\\\rpc_cluster_time_analysis.pdf'\n",
    "fully_massaged_df_with_time = fully_massaged_df[fully_massaged_df['end_time'] <= 350]\n",
    "ass.plot_time_differences_and_event_times(fully_massaged_df_with_time, pdf_path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_massaged_df_with_time = fully_massaged_df[fully_massaged_df['end_time'] <= 350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fully_massaged_df_with_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m show(\u001b[43mfully_massaged_df_with_time\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fully_massaged_df_with_time' is not defined"
     ]
    }
   ],
   "source": [
    "show(fully_massaged_df_with_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metric_for_combo(combo, rpc_heights):\n",
    "    locations = np.array([c['location'] for c in combo])\n",
    "    heights = np.array([rpc_heights[c['rpc']] for c in combo])\n",
    "    \n",
    "    if len(locations) > 1 and np.std(locations) > 0 and np.std(heights) > 0:\n",
    "        try:\n",
    "            coeffs, cov = np.polyfit(locations, heights, 1, cov=True)\n",
    "        except np.linalg.LinAlgError:\n",
    "            coeffs = [np.inf, np.inf]\n",
    "            cov = np.array([[np.inf, np.inf], [np.inf, np.inf]])\n",
    "            \n",
    "        slope, intercept = coeffs\n",
    "        slope_error, intercept_error = np.sqrt(np.diag(cov))\n",
    "        predicted = slope * locations + intercept\n",
    "        residuals = heights - predicted\n",
    "        RSS = np.sum(residuals ** 2)\n",
    "    else:\n",
    "        slope = intercept = slope_error = intercept_error = RSS = np.inf\n",
    "    \n",
    "    return slope, intercept, slope_error, intercept_error, RSS, combo\n",
    "\n",
    "def analyze_inter_rpc_hit_with_timing_adjusted(df):\n",
    "    rpc_time_offsets = {\n",
    "    ('rpc0', 'eta'): (7.94, 12.48),\n",
    "    ('rpc0', 'phi'): (-2.38, 13.69),\n",
    "    ('rpc1', 'eta'): (8.36, 12.22),\n",
    "    ('rpc1', 'phi'): (-3.79, 13.25),\n",
    "    ('rpc2', 'eta'): (8.84, 12.56),\n",
    "    ('rpc2', 'phi'): (-4.35, 13.57),\n",
    "    ('rpc3', 'eta'): (6.86, 12.41),\n",
    "    ('rpc3', 'phi'): (-4.3, 13.96),\n",
    "    ('rpc4', 'eta'): (2.7, 12.37),\n",
    "    ('rpc4', 'phi'): (-7.89, 13.41),\n",
    "    ('rpc5', 'eta'): (2.82, 13.05),\n",
    "    ('rpc5', 'phi'): (9.15, 14.14),\n",
    "}\n",
    "    paths = []\n",
    "\n",
    "    adjusted_muon_speed_cm_ns = 28\n",
    "\n",
    "    rpc_heights = {\n",
    "        'rpc0': 0, \n",
    "        'rpc1': 0.5, \n",
    "        'rpc2': 1.0, \n",
    "        'rpc3': 61.5, \n",
    "        'rpc4': 121.5, \n",
    "        'rpc5': 122.0\n",
    "    }\n",
    "\n",
    "    for event_number, event_group in df.groupby('event_number'):\n",
    "        for direction in ['eta', 'phi']:\n",
    "            direction_group = event_group[event_group['strip_direction'] == direction]\n",
    "            all_clusters = []\n",
    "\n",
    "            unique_rpcs = direction_group['rpc_number'].unique()\n",
    "            for rpc in unique_rpcs:\n",
    "                rpc_group = direction_group[direction_group['rpc_number'] == rpc]\n",
    "                for _, row in rpc_group.iterrows():\n",
    "                    location_scaling = 3.09375 if direction == 'eta' else 2.8125\n",
    "                    strip_locations = np.array(row['locations'])\n",
    "                    non_zero_locations = strip_locations[strip_locations != 0]\n",
    "                    if non_zero_locations.size > 0:\n",
    "                        strip_location = non_zero_locations[0] \n",
    "                    else:\n",
    "                        continue \n",
    "\n",
    "                    location = strip_location * location_scaling\n",
    "                    event_time = np.mean(row['times']) - rpc_time_offsets[(rpc, direction)][0]\n",
    "                    cluster_size_scaled = max(row['size'] * location_scaling, location_scaling) / 2\n",
    "                    all_clusters.append({\n",
    "                        'rpc': rpc,\n",
    "                        'location': location,\n",
    "                        'event_time': event_time,\n",
    "                        'uncertainty': cluster_size_scaled,\n",
    "                        'original_location': strip_location\n",
    "                    })\n",
    "\n",
    "            combination_metrics = []\n",
    "            valid_combinations = [] \n",
    "            for n in range(3, 6):\n",
    "                for combo in combinations(all_clusters, n):\n",
    "                    metric = calculate_metric_for_combo(combo, rpc_heights)\n",
    "                    if metric[4] != np.inf:\n",
    "                        combination_metrics.append(metric)\n",
    "                        \n",
    "            # Move filtering logic outside the loop so it's not reset each time\n",
    "            for combo_metric in combination_metrics:\n",
    "                combo = combo_metric[-1]\n",
    "                if len({c['rpc'] for c in combo}) < len(combo):\n",
    "                    continue\n",
    "\n",
    "                time_diffs_are_valid = True\n",
    "                for i in range(len(combo)):\n",
    "                    for j in range(i + 1, len(combo)):\n",
    "                        error_window = rpc_time_offsets[(combo[i]['rpc'], direction)][1] + rpc_time_offsets[(combo[j]['rpc'], direction)][1]\n",
    "                        \n",
    "                        # Use direct height differences\n",
    "                        height_diff = abs(rpc_heights[combo[i]['rpc']] - rpc_heights[combo[j]['rpc']])\n",
    "                        \n",
    "                        time_diff = abs(combo[i]['event_time'] - combo[j]['event_time'])\n",
    "                        expected_time_diff = height_diff / adjusted_muon_speed_cm_ns\n",
    "\n",
    "                        uncertainty_margin = 5\n",
    "                        # Use the expected time difference with the error window and uncertainty margin for validation\n",
    "                        if not (time_diff <= expected_time_diff + error_window + uncertainty_margin):\n",
    "                            time_diffs_are_valid = False\n",
    "                            break\n",
    "                    if not time_diffs_are_valid:\n",
    "                        break\n",
    "\n",
    "                if time_diffs_are_valid:\n",
    "                    valid_combinations.append(combo_metric)\n",
    "\n",
    "            for valid_combination in valid_combinations:\n",
    "                paths.append({\n",
    "                    'Event Number': event_number,\n",
    "                    'Direction': direction,\n",
    "                    'Slope': valid_combination[0],\n",
    "                    'Intercept': valid_combination[1],\n",
    "                    'Slope_error': valid_combination[2],\n",
    "                    'Intercept_error': valid_combination[3],\n",
    "                    'Used Coordinates': [(c['rpc'], c['original_location'], c['event_time']) for c in valid_combination[-1]],\n",
    "                    'RSS': valid_combination[4],\n",
    "                })\n",
    "\n",
    "    path_df = pd.DataFrame(paths)\n",
    "    return path_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def calculate_metric_for_combo(combo, rpc_heights):\n",
    "    locations = np.array([c['location'] for c in combo])\n",
    "    heights = np.array([rpc_heights[c['rpc']] for c in combo])\n",
    "    \n",
    "    if len(heights) > 1 and np.std(locations) > 0 and np.std(heights) > 0:\n",
    "        try:\n",
    "            coeffs, cov = np.polyfit(heights, locations, 1, cov=True)  \n",
    "        except np.linalg.LinAlgError:\n",
    "            coeffs = [np.inf, np.inf]\n",
    "            cov = np.array([[np.inf, np.inf], [np.inf, np.inf]])\n",
    "            \n",
    "        slope, intercept = coeffs\n",
    "        slope_error, intercept_error = np.sqrt(np.diag(cov))\n",
    "        predicted = slope * heights + intercept \n",
    "        residuals = locations - predicted\n",
    "        RSS = np.sum(residuals ** 2)\n",
    "    else:\n",
    "        slope = intercept = slope_error = intercept_error = RSS = np.inf\n",
    "    \n",
    "    return slope, intercept, slope_error, intercept_error, RSS, combo\n",
    "\n",
    "def analyze_inter_rpc_hit_with_timing_adjusted(df):\n",
    "    rpc_time_offsets = {\n",
    "    ('rpc0', 'eta'): (7.94, 12.48),\n",
    "    ('rpc0', 'phi'): (-2.38, 13.69),\n",
    "    ('rpc1', 'eta'): (8.36, 12.22),\n",
    "    ('rpc1', 'phi'): (-3.79, 13.25),\n",
    "    ('rpc2', 'eta'): (8.84, 12.56),\n",
    "    ('rpc2', 'phi'): (-4.35, 13.57),\n",
    "    ('rpc3', 'eta'): (6.86, 12.41),\n",
    "    ('rpc3', 'phi'): (-4.3, 13.96),\n",
    "    ('rpc4', 'eta'): (2.7, 12.37),\n",
    "    ('rpc4', 'phi'): (-7.89, 13.41),\n",
    "    ('rpc5', 'eta'): (2.82, 13.05),\n",
    "    ('rpc5', 'phi'): (9.15, 14.14),\n",
    "}\n",
    "    paths = []\n",
    "\n",
    "    adjusted_muon_speed_cm_ns = 28\n",
    "\n",
    "    rpc_heights = {\n",
    "        'rpc0': 0, \n",
    "        'rpc1': 0.5, \n",
    "        'rpc2': 1.0, \n",
    "        'rpc3': 61.5, \n",
    "        'rpc4': 121.5, \n",
    "        'rpc5': 122.0\n",
    "    }\n",
    "\n",
    "    for event_number, event_group in tqdm(df.groupby('event_number'), desc=\"Processing Events\"):\n",
    "        for direction in ['eta', 'phi']:\n",
    "            direction_group = event_group[event_group['strip_direction'] == direction]\n",
    "            all_clusters = []\n",
    "\n",
    "            unique_rpcs = direction_group['rpc_number'].unique()\n",
    "            for rpc in unique_rpcs:\n",
    "                rpc_group = direction_group[direction_group['rpc_number'] == rpc]\n",
    "                for _, row in rpc_group.iterrows():\n",
    "                    location_scaling = 3.09375 if direction == 'eta' else 2.8125\n",
    "                    strip_locations = np.array(row['locations'])\n",
    "                    non_zero_locations = strip_locations[strip_locations != 0]\n",
    "                    if non_zero_locations.size > 0:\n",
    "                        strip_location = non_zero_locations[0] \n",
    "                    else:\n",
    "                        continue \n",
    "\n",
    "                    location = strip_location * location_scaling\n",
    "                    event_time = np.mean(row['times']) - rpc_time_offsets[(rpc, direction)][0]\n",
    "                    cluster_size_scaled = max(row['size'] * location_scaling, location_scaling) / 2\n",
    "                    all_clusters.append({\n",
    "                        'rpc': rpc,\n",
    "                        'location': location,\n",
    "                        'event_time': event_time,\n",
    "                        'uncertainty': cluster_size_scaled,\n",
    "                        'original_location': strip_location\n",
    "                    })\n",
    "\n",
    "            combination_metrics = []\n",
    "            valid_combinations = [] \n",
    "            # for n in range(3, 3): \n",
    "            for combo in combinations(all_clusters, 3):\n",
    "                used_rpcs_set = {c['rpc'] for c in combo}\n",
    "                \n",
    "                if not used_rpcs_set.issubset({'rpc0', 'rpc1', 'rpc2'}):\n",
    "                    metric = calculate_metric_for_combo(combo, rpc_heights)\n",
    "        \n",
    "                    # Check RSS threshold here and ensure RPC combination uniqueness\n",
    "                    if metric[4] <= 6000 and len(used_rpcs_set) == len(combo):\n",
    "                        combination_metrics.append(metric)\n",
    "                        \n",
    "            # Move filtering logic outside the loop so it's not reset each time\n",
    "            for combo_metric in combination_metrics:\n",
    "                combo = combo_metric[-1]\n",
    "                if len({c['rpc'] for c in combo}) < len(combo):\n",
    "                    continue\n",
    "\n",
    "                time_diffs_are_valid = True\n",
    "                for i in range(len(combo)):\n",
    "                    for j in range(i + 1, len(combo)):\n",
    "                        error_window = rpc_time_offsets[(combo[i]['rpc'], direction)][1] + rpc_time_offsets[(combo[j]['rpc'], direction)][1]\n",
    "                        \n",
    "                        # Use direct height differences\n",
    "                        height_diff = abs(rpc_heights[combo[i]['rpc']] - rpc_heights[combo[j]['rpc']])\n",
    "                        \n",
    "                        time_diff = abs(combo[i]['event_time'] - combo[j]['event_time'])\n",
    "                        expected_time_diff = height_diff / adjusted_muon_speed_cm_ns\n",
    "\n",
    "                        uncertainty_margin = 5\n",
    "                        # Use the expected time difference with the error window and uncertainty margin for validation\n",
    "                        if not (time_diff <= expected_time_diff + error_window + uncertainty_margin):\n",
    "                            time_diffs_are_valid = False\n",
    "                            break\n",
    "                    if not time_diffs_are_valid:\n",
    "                        break\n",
    "\n",
    "                if time_diffs_are_valid:\n",
    "                    valid_combinations.append(combo_metric)\n",
    "\n",
    "            for valid_combination in valid_combinations:\n",
    "                paths.append({\n",
    "                    'Event Number': event_number,\n",
    "                    'Direction': direction,\n",
    "                    'Slope': valid_combination[0],\n",
    "                    'Intercept': valid_combination[1],\n",
    "                    'Slope_error': valid_combination[2],\n",
    "                    'Intercept_error': valid_combination[3],\n",
    "                    'Used Coordinates': [(c['rpc'], c['original_location'], c['event_time']) for c in valid_combination[-1]],\n",
    "                    'RSS': valid_combination[4],\n",
    "                })\n",
    "\n",
    "    path_df = pd.DataFrame(paths)\n",
    "    return path_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Events: 100%|██████████| 645/645 [00:02<00:00, 224.96it/s]\n"
     ]
    }
   ],
   "source": [
    "path_df = analyze_inter_rpc_hit_with_timing_adjusted(fully_massaged_df_with_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "INFO:pandasgui.gui:Opening PandasGUI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x1e6a74f5120>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_paths(df):\n",
    "    excluded_triplet = {'rpc0', 'rpc1', 'rpc2'}\n",
    "\n",
    "    rows_to_drop = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        used_rpcs = set(c[0] for c in row['Used Coordinates'])\n",
    "\n",
    "        if used_rpcs.issubset(excluded_triplet):\n",
    "            rows_to_drop.append(index)  \n",
    "        elif row['RSS'] > 5:\n",
    "            rows_to_drop.append(index) \n",
    "    \n",
    "    # Drop the rows from the DataFrame\n",
    "    filtered_df = df.drop(rows_to_drop).reset_index(drop=True)\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "INFO:pandasgui.gui:Opening PandasGUI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x1e6a834f400>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataframe = filter_paths(path_df)\n",
    "\n",
    "show(filtered_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m eta_df \u001b[38;5;241m=\u001b[39m \u001b[43mfiltered_dataframe\u001b[49m[filtered_dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDirection\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m angles_y_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m90\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdegrees(np\u001b[38;5;241m.\u001b[39marctan(eta_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSlope\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m      3\u001b[0m angles_y_axis_adjusted \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(angles_y_axis \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m90\u001b[39m, angles_y_axis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m180\u001b[39m, angles_y_axis)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtered_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "eta_df = filtered_dataframe[filtered_dataframe['Direction'] == 'eta']\n",
    "angles_y_axis = 90 - np.degrees(np.arctan(eta_df['Slope']))\n",
    "angles_y_axis_adjusted = np.where(angles_y_axis > 90, angles_y_axis - 180, angles_y_axis)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(angles_y_axis_adjusted, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('angles (degrees)')\n",
    "plt.ylabel('Occurance')\n",
    "plt.title('Cross_Chamber_Angular_Distribution')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_df = filtered_dataframe[filtered_dataframe['Direction'] == 'phi']\n",
    "angles = np.degrees(np.arctan(phi_df['Slope']))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(angles, bins=200, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('angles (degrees)')\n",
    "plt.ylabel('Occurance')\n",
    "plt.title('Cross_Chamber_Angular_Distribution_phi')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "INFO:pandasgui.gui:Opening PandasGUI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x22fdbc4f880>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(filtered_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
