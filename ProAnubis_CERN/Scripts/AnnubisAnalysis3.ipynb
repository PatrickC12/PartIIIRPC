{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot activate multiple GUI eventloops\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'AnubisSuperScript' from 'c:\\\\Users\\\\Peter\\\\OneDrive - University of Cambridge\\\\Desktop\\\\Project Excel Work\\\\PartIIIRPC\\\\ProAnubis_CERN\\\\Scripts\\\\AnubisSuperScript.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import anubisPlotUtils as anPlot\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import hist as hi\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "import matplotlib.colors as colors\n",
    "matplotlib.use('TkAgg')  # or 'Qt5Agg', 'GTK3Agg', etc.\n",
    "import mplhep as hep\n",
    "hep.style.use([hep.style.ATLAS])\n",
    "import sys\n",
    "import AnalysisToolAnubis as AT\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from pandasgui import show\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.ndimage import label, find_objects\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import sys\n",
    "from scipy.stats import gaussian_kde\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import AnubisSuperScript as ass\n",
    "from functools import partial\n",
    "import importlib\n",
    "importlib.reload(ass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mapping = {\n",
    "    0: {\n",
    "        (0, 31): ('rpc0', 'eta'),\n",
    "        (32, 63): ('rpc0', 'phi1'),\n",
    "        (64, 95): ('rpc0', 'phi2'),\n",
    "        (96, 127): ('rpc1', 'eta'),\n",
    "    },\n",
    "    1: {\n",
    "        (0, 31): ('rpc1', 'phi1'),\n",
    "        (32, 63): ('rpc1', 'phi2'),\n",
    "        (64, 95): ('rpc2', 'eta'),\n",
    "        (96, 127): ('rpc2', 'phi1'),\n",
    "    },\n",
    "    2: {\n",
    "        (0, 31): ('rpc2', 'phi2'),\n",
    "        (32, 63): ('rpc3', 'eta'),\n",
    "        (64, 95): ('rpc3', 'phi1'),\n",
    "        (96, 127): ('rpc3', 'phi2'),\n",
    "    },\n",
    "    3: {\n",
    "        (0, 31): ('rpc4', 'eta'),\n",
    "        (32, 63): ('rpc4', 'phi1'),\n",
    "        (64, 95): ('rpc4', 'phi2'),\n",
    "        (96, 127): ('rpc5', 'eta'),\n",
    "    },\n",
    "    4: {\n",
    "        (0, 31): ('rpc5', 'phi1'),\n",
    "        (32, 63): ('rpc5', 'phi2'),\n",
    "    },\n",
    "}\n",
    "\n",
    "strips_on_steroid = {\n",
    "    'rpc0': {'phi': [0]},\n",
    "    'rpc1': {'phi': [0]},\n",
    "    'rpc2': {'phi': [0]},\n",
    "    'rpc3': {'phi': [0]},\n",
    "    'rpc4': {'eta': [31,0], 'phi': [0]},\n",
    "    'rpc5': {'eta': [31,0], 'phi': [0]},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisData = AT.importDatafile('C:\\\\Users\\\\Peter\\\\OneDrive - University of Cambridge\\\\Desktop\\\\Project Excel Work\\\\PartIIIRPC\\\\ProAnubis_CERN\\\\ProAnubisData\\\\60sRun_24_3_4.h5')\n",
    "df = ass.remake_data(thisData, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = ass.calculate_cluster_metrics_better(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_noisy_strips_with_map = partial(ass.remove_noisy_strips, noisy_strips=strips_on_steroid)\n",
    "anti_steriod_df = cluster_df[cluster_df.apply(lambda row: remove_noisy_strips_with_map(row), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_massaged_df = anti_steriod_df[anti_steriod_df['size'] <= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(anti_steriod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "INFO:pandasgui.gui:Opening PandasGUI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x23406a801f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(fully_massaged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "INFO:pandasgui.gui:Opening PandasGUI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x1f385eda560>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(cluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path1 = 'C:\\\\Users\\\\Peter\\\\OneDrive - University of Cambridge\\\\Desktop\\\\Project Excel Work\\\\PartIIIRPC\\\\ProAnubis_CERN\\\\ProAnubis Plots\\\\Olegs Groceries\\\\rpc_cluster_analysis_all.pdf'\n",
    "pdf_path2 = 'C:\\\\Users\\\\Peter\\\\OneDrive - University of Cambridge\\\\Desktop\\\\Project Excel Work\\\\PartIIIRPC\\\\ProAnubis_CERN\\\\ProAnubis Plots\\\\Olegs Groceries\\\\rpc_cluster_analysis_anti_steriod.pdf'\n",
    "# ass.plot_rpc_histograms(cluster_df, pdf_path1)\n",
    "ass.plot_rpc_histograms(anti_steriod_df, pdf_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Peter\\OneDrive - University of Cambridge\\Desktop\\Project Excel Work\\PartIIIRPC\\ProAnubis_CERN\\Scripts\\AnubisSuperScript.py:466: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  midpoints_series = pd.Series(all_cluster_midpoints)\n",
      "c:\\Users\\Peter\\OneDrive - University of Cambridge\\Desktop\\Project Excel Work\\PartIIIRPC\\ProAnubis_CERN\\Scripts\\AnubisSuperScript.py:466: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  midpoints_series = pd.Series(all_cluster_midpoints)\n",
      "c:\\Users\\Peter\\OneDrive - University of Cambridge\\Desktop\\Project Excel Work\\PartIIIRPC\\ProAnubis_CERN\\Scripts\\AnubisSuperScript.py:466: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  midpoints_series = pd.Series(all_cluster_midpoints)\n",
      "c:\\Users\\Peter\\OneDrive - University of Cambridge\\Desktop\\Project Excel Work\\PartIIIRPC\\ProAnubis_CERN\\Scripts\\AnubisSuperScript.py:466: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  midpoints_series = pd.Series(all_cluster_midpoints)\n",
      "c:\\Users\\Peter\\OneDrive - University of Cambridge\\Desktop\\Project Excel Work\\PartIIIRPC\\ProAnubis_CERN\\Scripts\\AnubisSuperScript.py:466: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  midpoints_series = pd.Series(all_cluster_midpoints)\n",
      "c:\\Users\\Peter\\OneDrive - University of Cambridge\\Desktop\\Project Excel Work\\PartIIIRPC\\ProAnubis_CERN\\Scripts\\AnubisSuperScript.py:466: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  midpoints_series = pd.Series(all_cluster_midpoints)\n"
     ]
    }
   ],
   "source": [
    "pdf_path3 = 'C:\\\\Users\\\\Peter\\\\OneDrive - University of Cambridge\\\\Desktop\\\\Project Excel Work\\\\PartIIIRPC\\\\ProAnubis_CERN\\\\ProAnubis Plots\\\\Olegs Groceries\\\\rpc_cluster_analysis_by_size.pdf'\n",
    "ass.plot_rpc_histograms_by_cluster_size(anti_steriod_df, pdf_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path4 = 'C:\\\\Users\\\\Peter\\\\OneDrive - University of Cambridge\\\\Desktop\\\\Project Excel Work\\\\PartIIIRPC\\\\ProAnubis_CERN\\\\ProAnubis Plots\\\\Olegs Groceries\\\\rpc_cluster_time_analysis.pdf'\n",
    "fully_massaged_df_with_time = fully_massaged_df[fully_massaged_df['end_time'] <= 350]\n",
    "ass.plot_time_differences_and_event_times(fully_massaged_df_with_time, pdf_path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_massaged_df_with_time = fully_massaged_df[fully_massaged_df['end_time'] <= 350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fully_massaged_df_with_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m show(\u001b[43mfully_massaged_df_with_time\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fully_massaged_df_with_time' is not defined"
     ]
    }
   ],
   "source": [
    "show(fully_massaged_df_with_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metric_for_combo(combo, rpc_heights):\n",
    "    locations = np.array([c['location'] for c in combo])\n",
    "    heights = np.array([rpc_heights[c['rpc']] for c in combo])\n",
    "\n",
    "    try:\n",
    "        coeffs, cov = np.polyfit(locations, heights, 1, cov=True)\n",
    "        slope, intercept = coeffs\n",
    "        slope_error, intercept_error = np.sqrt(np.diag(cov))\n",
    "        predicted = slope * locations + intercept\n",
    "        residuals = heights - predicted\n",
    "        RSS = np.sum(residuals ** 2)\n",
    "    except np.linalg.LinAlgError:\n",
    "        slope = np.inf\n",
    "        intercept = np.inf\n",
    "        slope_error, intercept_error = np.inf, np.inf\n",
    "        RSS = np.inf\n",
    "    \n",
    "    # combined_uncertainty = np.sum(uncertainties)\n",
    "    return slope, intercept, slope_error, intercept_error,RSS, combo\n",
    "\n",
    "def analyze_inter_rpc_hit_with_timing_adjusted(df):\n",
    "    rpc_time_offsets = {\n",
    "    ('rpc0', 'eta'): (7.94, 12.48),\n",
    "    ('rpc0', 'phi'): (-2.38, 13.69),\n",
    "    ('rpc1', 'eta'): (8.36, 12.22),\n",
    "    ('rpc1', 'phi'): (-3.79, 13.25),\n",
    "    ('rpc2', 'eta'): (8.84, 12.56),\n",
    "    ('rpc2', 'phi'): (-4.35, 13.57),\n",
    "    ('rpc3', 'eta'): (6.86, 12.41),\n",
    "    ('rpc3', 'phi'): (-4.3, 13.96),\n",
    "    ('rpc4', 'eta'): (2.7, 12.37),\n",
    "    ('rpc4', 'phi'): (-7.89, 13.41),\n",
    "    ('rpc5', 'eta'): (2.82, 13.05),\n",
    "    ('rpc5', 'phi'): (9.15, 14.14),\n",
    "}\n",
    "    paths = []\n",
    "\n",
    "    adjusted_muon_speed_cm_ns = 28\n",
    "\n",
    "    rpc_heights = {\n",
    "        'rpc0': 0, \n",
    "        'rpc1': 0.5, \n",
    "        'rpc2': 1.0, \n",
    "        'rpc3': 61.5, \n",
    "        'rpc4': 121.5, \n",
    "        'rpc5': 122.0\n",
    "    }\n",
    "\n",
    "    for event_number, event_group in df.groupby('event_number'):\n",
    "        for direction in ['eta', 'phi']:\n",
    "            direction_group = event_group[event_group['strip_direction'] == direction]\n",
    "            all_clusters = []\n",
    "\n",
    "            unique_rpcs = direction_group['rpc_number'].unique()\n",
    "            for rpc in unique_rpcs:\n",
    "                rpc_group = direction_group[direction_group['rpc_number'] == rpc]\n",
    "                for _, row in rpc_group.iterrows():\n",
    "                    location_scaling = 3.09375 if direction == 'eta' else 2.8125\n",
    "                    strip_locations = np.array(row['locations'])\n",
    "                    non_zero_locations = strip_locations[strip_locations != 0]\n",
    "                    if non_zero_locations.size > 0:\n",
    "                        strip_location = non_zero_locations[0] \n",
    "                    else:\n",
    "                        continue \n",
    "\n",
    "                    location = strip_location * location_scaling\n",
    "                    event_time = np.mean(row['times']) - rpc_time_offsets[(rpc, direction)][0]\n",
    "                    cluster_size_scaled = max(row['size'] * location_scaling, location_scaling) / 2\n",
    "                    all_clusters.append({\n",
    "                        'rpc': rpc,\n",
    "                        'location': location,\n",
    "                        'event_time': event_time,\n",
    "                        'uncertainty': cluster_size_scaled,\n",
    "                        'original_location': strip_location\n",
    "                    })\n",
    "\n",
    "            combination_metrics = []\n",
    "            valid_combinations = [] \n",
    "            for n in range(3, 6):\n",
    "                for combo in combinations(all_clusters, n):\n",
    "                    metric = calculate_metric_for_combo(combo, rpc_heights)\n",
    "                    if metric[4] != np.inf:\n",
    "                        combination_metrics.append(metric)\n",
    "                        \n",
    "            # Move filtering logic outside the loop so it's not reset each time\n",
    "            for combo_metric in combination_metrics:\n",
    "                combo = combo_metric[-1]\n",
    "                if len({c['rpc'] for c in combo}) < len(combo):\n",
    "                    continue\n",
    "\n",
    "                time_diffs_are_valid = True\n",
    "                for i in range(len(combo)):\n",
    "                    for j in range(i + 1, len(combo)):\n",
    "                        error_window = rpc_time_offsets[(combo[i]['rpc'], direction)][1] + rpc_time_offsets[(combo[j]['rpc'], direction)][1]\n",
    "                        \n",
    "                        # Use direct height differences\n",
    "                        height_diff = abs(rpc_heights[combo[i]['rpc']] - rpc_heights[combo[j]['rpc']])\n",
    "                        \n",
    "                        time_diff = abs(combo[i]['event_time'] - combo[j]['event_time'])\n",
    "                        expected_time_diff = height_diff / adjusted_muon_speed_cm_ns\n",
    "\n",
    "                        uncertainty_margin = 5\n",
    "                        # Use the expected time difference with the error window and uncertainty margin for validation\n",
    "                        if not (time_diff <= expected_time_diff + error_window + uncertainty_margin):\n",
    "                            time_diffs_are_valid = False\n",
    "                            break\n",
    "                    if not time_diffs_are_valid:\n",
    "                        break\n",
    "\n",
    "                if time_diffs_are_valid:\n",
    "                    valid_combinations.append(combo_metric)\n",
    "\n",
    "            for valid_combination in valid_combinations:\n",
    "                paths.append({\n",
    "                    'Event Number': event_number,\n",
    "                    'Direction': direction,\n",
    "                    'Slope': valid_combination[0],\n",
    "                    'Intercept': valid_combination[1],\n",
    "                    'Slope_error': valid_combination[2],\n",
    "                    'Intercept_error': valid_combination[3],\n",
    "                    'Used Coordinates': [(c['rpc'], c['original_location'], c['event_time']) for c in valid_combination[-1]],\n",
    "                    'RSS': valid_combination[4],\n",
    "                })\n",
    "\n",
    "    path_df = pd.DataFrame(paths)\n",
    "    return path_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\AppData\\Local\\Temp\\ipykernel_37660\\1504677970.py:6: RankWarning: Polyfit may be poorly conditioned\n",
      "  coeffs, cov = np.polyfit(locations, heights, 1, cov=True)\n"
     ]
    }
   ],
   "source": [
    "path_df = analyze_inter_rpc_hit_with_timing_adjusted(fully_massaged_df_with_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "INFO:pandasgui.gui:Opening PandasGUI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x2340625ef80>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_paths(df):\n",
    "    excluded_triplet = {'rpc0', 'rpc1', 'rpc2'}\n",
    "\n",
    "    rows_to_drop = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        used_rpcs = set(c[0] for c in row['Used Coordinates'])\n",
    "\n",
    "        if used_rpcs.issubset(excluded_triplet):\n",
    "            rows_to_drop.append(index)  \n",
    "        elif row['RSS'] > 6000:\n",
    "            rows_to_drop.append(index) \n",
    "    \n",
    "    # Drop the rows from the DataFrame\n",
    "    filtered_df = df.drop(rows_to_drop).reset_index(drop=True)\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataframe = filter_paths(path_df)\n",
    "\n",
    "# show(filtered_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\AppData\\Local\\Temp\\ipykernel_33260\\3662085476.py:37: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(figsize = (20, 12))\n"
     ]
    }
   ],
   "source": [
    "filtered_df = filtered_dataframe.copy()\n",
    "\n",
    "def filter_paths():\n",
    "    global filtered_df\n",
    "    excluded_triplet = {'rpc0', 'rpc1', 'rpc2'}\n",
    "\n",
    "    rows_to_drop = []\n",
    "\n",
    "    for index, row in filtered_df.iterrows():\n",
    "        used_rpcs = set(c[0] for c in row['Used Coordinates'])\n",
    "\n",
    "        if used_rpcs.issubset(excluded_triplet):\n",
    "            rows_to_drop.append(index)\n",
    "        elif row['RSS'] > 600:\n",
    "            rows_to_drop.append(index)\n",
    "\n",
    "    filtered_df = filtered_df.drop(rows_to_drop).reset_index(drop=True)\n",
    "    update_plot(0)\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"RPC Event Viewer\")\n",
    "root.geometry(\"800x600\")\n",
    "\n",
    "frame = tk.Frame(root)\n",
    "frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "current_index = tk.IntVar(value=0)\n",
    "current_direction = tk.StringVar(value='eta')\n",
    "selected_hits = tk.IntVar(value=3)\n",
    "\n",
    "def plot_event(index):\n",
    "    global filtered_df\n",
    "    event = filtered_df.iloc[index]\n",
    "    if event['Direction'] != current_direction.get() or len(event['Used Coordinates']) != selected_hits.get():\n",
    "        return None\n",
    "    fig, ax = plt.subplots(figsize = (20, 12))\n",
    "    x_limits = (-99, 0) if current_direction.get() == 'eta' else (0, 180)\n",
    "    \n",
    "    location_scaling = 3.09375 if current_direction.get() == 'eta' else 2.8125\n",
    "\n",
    "    rpc_heights = {'rpc0': 0, 'rpc1': 0.5, 'rpc2': 1, 'rpc3': 61.5, 'rpc4': 121.5, 'rpc5': 122}\n",
    "    \n",
    "    for rpc, height in rpc_heights.items():\n",
    "        ax.hlines(y=height, xmin=x_limits[0], xmax=x_limits[1], color='gray', linestyle='--')\n",
    "    \n",
    "    for coord in event['Used Coordinates']:\n",
    "        rpc, location, _ = coord\n",
    "        scaled_location = location * location_scaling\n",
    "        if x_limits[0] <= scaled_location <= x_limits[1]:\n",
    "            ax.plot(scaled_location, rpc_heights[rpc], 'ro')\n",
    "            \n",
    "    if current_direction.get() == 'eta':\n",
    "        x_vals = np.linspace(-99, 0, 500)  \n",
    "    else: \n",
    "        x_vals = np.linspace(0, 180, 500) \n",
    "\n",
    "    y_vals = event['Slope'] * x_vals + event['Intercept']\n",
    "    ax.plot(x_vals, y_vals, 'b-')  \n",
    "    \n",
    "    ax.set_xlim(x_limits)\n",
    "    ax.set_ylim(-1, max(rpc_heights.values()) + 1)\n",
    "    ax.set_xlabel('Location')\n",
    "    ax.set_ylabel('Height')\n",
    "    ax.set_title(f'index {index} (Number: {event[\"Event Number\"]}) Direction: {event[\"Direction\"]}')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def update_plot(index):\n",
    "    global current_index\n",
    "    if index < 0 or index >= len(filtered_df):\n",
    "        return\n",
    "    current_index.set(index)\n",
    "    fig = plot_event(index)\n",
    "    if fig is None: \n",
    "        return\n",
    "    canvas = FigureCanvasTkAgg(fig, master=frame)\n",
    "    widget = canvas.get_tk_widget()\n",
    "    widget.grid(row=1, column=0, columnspan=5, sticky='nsew')\n",
    "    canvas.draw()\n",
    "    \n",
    "def filter_and_update():\n",
    "    global filtered_df\n",
    "    hits_filter = selected_hits.get()\n",
    "    filtered_df = filtered_df[filtered_df['Used Coordinates'].apply(len) == hits_filter]\n",
    "    update_plot(0)\n",
    "\n",
    "def navigate(direction):\n",
    "    global filtered_df\n",
    "    new_index = current_index.get() + direction\n",
    "    while 0 <= new_index < len(filtered_df):\n",
    "        if filtered_df.iloc[new_index]['Direction'] == current_direction.get():\n",
    "            update_plot(new_index)\n",
    "            break\n",
    "        new_index += direction\n",
    "\n",
    "    current_index.set(new_index)\n",
    "\n",
    "def go_to_index():\n",
    "    index = int(entry_index.get())\n",
    "    update_plot(index)\n",
    "    \n",
    "current_direction = tk.StringVar(value='eta')\n",
    "\n",
    "\n",
    "def toggle_direction():\n",
    "    global filtered_df\n",
    "    current_direction.set('phi' if current_direction.get() == 'eta' else 'eta')\n",
    "    new_direction_events = filtered_df[filtered_df['Direction'] == current_direction.get()]\n",
    "    if not new_direction_events.empty:\n",
    "        first_relevant_index = new_direction_events.index[0]\n",
    "        current_index.set(first_relevant_index)\n",
    "        update_plot(first_relevant_index)\n",
    "    else:\n",
    "        print(\"No events found in the new direction.\")\n",
    "        \n",
    "label_hits = tk.Label(frame, text=\"Select number of hits:\")\n",
    "label_hits.grid(row=2, column=0)\n",
    "\n",
    "combo_hits = ttk.Combobox(frame, textvariable=selected_hits)\n",
    "combo_hits['values'] = (3, 4, 5, 6) \n",
    "combo_hits.grid(row=2, column=1)\n",
    "\n",
    "# Button to apply the hits filter\n",
    "button_apply_hits = tk.Button(frame, text=\"Apply Filter\", command=filter_and_update)\n",
    "button_apply_hits.grid(row=2, column=2)\n",
    "\n",
    "button_direction = tk.Button(frame, text=\"Toggle Direction (eta/phi)\", command=toggle_direction)\n",
    "button_direction.grid(row=0, column=4, sticky='ew')\n",
    "\n",
    "button_prev = tk.Button(frame, text=\"<< Previous\", command=lambda: navigate(-1))\n",
    "button_prev.grid(row=0, column=0)\n",
    "\n",
    "button_next = tk.Button(frame, text=\"Next >>\", command=lambda: navigate(1))\n",
    "button_next.grid(row=0, column=3)\n",
    "\n",
    "entry_index = tk.Entry(frame)\n",
    "entry_index.grid(row=0, column=1)\n",
    "\n",
    "button_go = tk.Button(frame, text=\"Go to Index\", command=go_to_index)\n",
    "button_go.grid(row=0, column=2)\n",
    "\n",
    "update_plot(0)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_df = filtered_dataframe[filtered_dataframe['Direction'] == 'eta']\n",
    "angles = np.degrees(np.arctan(eta_df['Slope']))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(angles, bins=200, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('angles (degrees)')\n",
    "plt.ylabel('Occurance')\n",
    "plt.title('Cross_Chamber_Angular_Distribution')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_df = filtered_dataframe[filtered_dataframe['Direction'] == 'phi']\n",
    "angles = np.degrees(np.arctan(phi_df['Slope']))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(angles, bins=200, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('angles (degrees)')\n",
    "plt.ylabel('Occurance')\n",
    "plt.title('Cross_Chamber_Angular_Distribution_phi')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "INFO:pandasgui.gui:Opening PandasGUI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x22fdbc4f880>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(filtered_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
